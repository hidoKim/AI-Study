{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da972686-cb5c-424b-b603-6a35c7ab5b28",
   "metadata": {},
   "source": [
    "## wine 예제, 하이퍼파라미터 튜닝 후 MLP 딥러닝 분류 \n",
    "### + 원-핫 인코딩\n",
    "원-핫 인코딩은 분류에서만 사용됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "e288f0c7-4256-4fe0-b5de-b144ad7120fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import kerastuner as kt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Input\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dff981c-97d9-4981-801c-f80d7f6c8855",
   "metadata": {},
   "source": [
    "### CSV파일 로딩하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "ba8c3eea-24e4-4036-ab0b-aaf71acfa245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wine</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic.acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Acl</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid.phenols</th>\n",
       "      <th>Proanth</th>\n",
       "      <th>Color.int</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>3</td>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>3</td>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>3</td>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>3</td>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>3</td>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Wine  Alcohol  Malic.acid   Ash   Acl   Mg  Phenols  Flavanoids  \\\n",
       "0       1    14.23        1.71  2.43  15.6  127     2.80        3.06   \n",
       "1       1    13.20        1.78  2.14  11.2  100     2.65        2.76   \n",
       "2       1    13.16        2.36  2.67  18.6  101     2.80        3.24   \n",
       "3       1    14.37        1.95  2.50  16.8  113     3.85        3.49   \n",
       "4       1    13.24        2.59  2.87  21.0  118     2.80        2.69   \n",
       "..    ...      ...         ...   ...   ...  ...      ...         ...   \n",
       "173     3    13.71        5.65  2.45  20.5   95     1.68        0.61   \n",
       "174     3    13.40        3.91  2.48  23.0  102     1.80        0.75   \n",
       "175     3    13.27        4.28  2.26  20.0  120     1.59        0.69   \n",
       "176     3    13.17        2.59  2.37  20.0  120     1.65        0.68   \n",
       "177     3    14.13        4.10  2.74  24.5   96     2.05        0.76   \n",
       "\n",
       "     Nonflavanoid.phenols  Proanth  Color.int   Hue    OD  Proline  \n",
       "0                    0.28     2.29       5.64  1.04  3.92     1065  \n",
       "1                    0.26     1.28       4.38  1.05  3.40     1050  \n",
       "2                    0.30     2.81       5.68  1.03  3.17     1185  \n",
       "3                    0.24     2.18       7.80  0.86  3.45     1480  \n",
       "4                    0.39     1.82       4.32  1.04  2.93      735  \n",
       "..                    ...      ...        ...   ...   ...      ...  \n",
       "173                  0.52     1.06       7.70  0.64  1.74      740  \n",
       "174                  0.43     1.41       7.30  0.70  1.56      750  \n",
       "175                  0.43     1.35      10.20  0.59  1.56      835  \n",
       "176                  0.53     1.46       9.30  0.60  1.62      840  \n",
       "177                  0.56     1.35       9.20  0.61  1.60      560  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = './wine.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "3dd5a8a4-095e-48da-8614-b913b5d99d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (178, 14)\n",
      "columns: Index(['Wine', 'Alcohol', 'Malic.acid', 'Ash', 'Acl', 'Mg', 'Phenols',\n",
      "       'Flavanoids', 'Nonflavanoid.phenols', 'Proanth', 'Color.int', 'Hue',\n",
      "       'OD', 'Proline'],\n",
      "      dtype='object')\n",
      "=== 결측치 현황 ===\n",
      "Wine                    0\n",
      "Alcohol                 0\n",
      "Malic.acid              0\n",
      "Ash                     0\n",
      "Acl                     0\n",
      "Mg                      0\n",
      "Phenols                 0\n",
      "Flavanoids              0\n",
      "Nonflavanoid.phenols    0\n",
      "Proanth                 0\n",
      "Color.int               0\n",
      "Hue                     0\n",
      "OD                      0\n",
      "Proline                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"shape:\", df.shape)\n",
    "print(\"columns:\", df.columns)\n",
    "# 결측치 확인\n",
    "print(\"=== 결측치 현황 ===\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "1361f94d-c0ed-4a07-aa10-cca1a95a644b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 레이블 분포 ===\n",
      "Wine\n",
      "2    71\n",
      "1    59\n",
      "3    48\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 레이블 분포 확인\n",
    "print(\"\\n=== 레이블 분포 ===\")\n",
    "print(df['Wine'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8137b239-04c5-4f95-8c94-ecc80086a1c6",
   "metadata": {},
   "source": [
    "### 특성과 타켓(레이블) 분리\n",
    "X: 특성\n",
    "y: 타겟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "caf54bf6-1e80-4b36-9145-f96de0405a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Wine', axis=1).values # Pandas DataFrame을 NumPy 배열로 변환, wine 제외\n",
    "y = df['Wine'].values\n",
    "\n",
    "# 훈련 및 테스트 세트 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6025fa04-4ec5-43a3-84d2-c2ce7ad4d6b7",
   "metadata": {},
   "source": [
    "### 타겟변수 (Y) 원핫 인코딩 수행 \n",
    "타겟변수 (Y)를 다중 클래스 분류에 적합한 형태로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "d8538d31-2b36-408f-81aa-52dc2c3935df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블 원-핫 인코딩 (분할 후 수행)\n",
    "y_train_onehot = to_categorical(y_train - 1)  # 훈련 데이터 인코딩\n",
    "y_test_onehot = to_categorical(y_test - 1)    # 테스트 데이터 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37433b14-6d40-482d-a861-a5d7c835865f",
   "metadata": {},
   "source": [
    "#### 데이터 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "c27cafab-1950-4d8c-a683-6384ea38288d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # 훈련 데이터로 학습\n",
    "X_test_scaled = scaler.transform(X_test)        # 테스트 데이터 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "1b50ffef-825e-48de-8012-0c7835de32a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 데이터셋 Shape ===\n",
      "X_train shape: (142, 13)\n",
      "X_test shape: (36, 13)\n",
      "y_train shape: (142, 3)\n",
      "y_test shape: (36, 3)\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 Shape 확인\n",
    "print(\"\\n=== 데이터셋 Shape ===\")\n",
    "print(\"X_train shape:\", X_train_scaled.shape)\n",
    "print(\"X_test shape:\", X_test_scaled.shape)\n",
    "print(\"y_train shape:\", y_train_onehot.shape)\n",
    "print(\"y_test shape:\", y_test_onehot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72666947-9dfa-4dbe-b47c-a270da04b413",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터 튜닝 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a0f667-4734-4d0c-bd49-09cf485495cc",
   "metadata": {},
   "source": [
    "#### 모델 구조 정의\n",
    "hp.int() : 정수 범위 내에서 최적의 노드 수 탐색\n",
    "\n",
    "hp.choice(): 옵티마이저(adam/sgd) 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "69c9ffe7-b011-49eb-be1e-6a8c87122d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원-핫 인코딩 후 클래스 수 계산\n",
    "num_classes = y_train_onehot.shape[1]  # 클래스 개수 (예: 3)\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train.shape[1],))) # 입력층(Input): 특성 수만큼 노드 설정\n",
    "    # 첫번째 은닉층: 32~128개의 노드 중 최적값 탐색 (32단위)\n",
    "    model.add(Dense(hp.Int('units_1', min_value=32, max_value=128, step=32), activation='relu'))\n",
    "    # 두번째 은닉층: 16~64개의 노드 중 최적값 탐색 (16단위)\n",
    "    model.add(Dense(hp.Int('units_2', min_value=16, max_value=64, step=16), activation='relu'))\n",
    "    # 출력층: 클래스 수만큼 노드 + 소프트맥스 활성화(다중 분류)\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "    # 컴파일: 옵티마이저(adam, sgd)탐색\n",
    "    model.compile(\n",
    "        optimizer=hp.Choice('optimizer', values=['adam', 'sgd']),\n",
    "        loss='categorical_crossentropy', # 다중 클래스 분류용 손실 함수\n",
    "        metrics=['accuracy'] # 성능 확인 지표 (정확도 + 정밀도)\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce2fdbb-7f47-4a39-a7f1-504f71352da6",
   "metadata": {},
   "source": [
    "#### 튜닝 디렉토리 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "b47a9d40-881f-40a1-ae6f-9f6576dcb254",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(\"my_tuning_dir\", ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722312ba-0256-4d6c-8d12-0c127dfb5b9e",
   "metadata": {},
   "source": [
    "#### Keras Tuner 설정 (하이퍼파라미터 탐색 설정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "08880357-dbda-4575-8c15-3cf3046b0423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 무작위로 하이퍼파라미터 조합을 시도함\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy', # 검증 정확도 최대화\n",
    "    max_trials=10, # 총 10번 실험\n",
    "    directory='my_tuning_dir', # 결과 저장 경로\n",
    "    project_name='wine_classification', # 이름\n",
    "    overwrite=True # 기존 데이터 덮어쓰기 (KeyError해결)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5904b89-c5bf-466c-be45-7850896a4b18",
   "metadata": {},
   "source": [
    "#### 하이퍼파라미터 탐색 수행\n",
    "- epochs=50 : 각 실험별 50회 학습\n",
    "- batch_size=32 : 미니 배치 크기 32\n",
    "- validation_split=0.2 : 훈련 데이터의 20%를 검증용으로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "861a0637-3a0b-4357-9ac4-06b2992cb6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 03s]\n",
      "val_accuracy: 0.9655172228813171\n",
      "\n",
      "Best val_accuracy So Far: 1.0\n",
      "Total elapsed time: 00h 00m 36s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train_scaled, y_train_onehot, epochs=50, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca5e337-6f1a-4b4c-b593-455c30aaa634",
   "metadata": {},
   "source": [
    "#### 최적의 하이퍼파라미터 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "960b3224-5cbf-41e5-af8b-36eb61ab600f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters:\n",
      "첫 번째 은닉층 노드 수: 32\n",
      "두 번째 은닉층 노드 수: 64\n",
      "Optimizer: adam\n"
     ]
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(f\"첫 번째 은닉층 노드 수: {best_hps.get('units_1')}\")\n",
    "print(f\"두 번째 은닉층 노드 수: {best_hps.get('units_2')}\")\n",
    "print(f\"Optimizer: {best_hps.get('optimizer')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb17958a-c693-429f-8517-fcbabe482208",
   "metadata": {},
   "source": [
    "#### 최적의 하이퍼파라미터로 MLP 딥러닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "05e17f2d-474a-47cd-a935-46b4d1f2d302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5091 - loss: 1.0524 - val_accuracy: 0.5862 - val_loss: 0.8545\n",
      "Epoch 2/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6299 - loss: 0.7984 - val_accuracy: 0.7241 - val_loss: 0.6402\n",
      "Epoch 3/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7519 - loss: 0.6325 - val_accuracy: 0.8276 - val_loss: 0.4997\n",
      "Epoch 4/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9052 - loss: 0.4494 - val_accuracy: 0.8276 - val_loss: 0.4070\n",
      "Epoch 5/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8829 - loss: 0.3750 - val_accuracy: 0.8276 - val_loss: 0.3427\n",
      "Epoch 6/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9196 - loss: 0.3343 - val_accuracy: 0.8276 - val_loss: 0.2924\n",
      "Epoch 7/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9144 - loss: 0.2779 - val_accuracy: 0.8966 - val_loss: 0.2534\n",
      "Epoch 8/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9367 - loss: 0.2597 - val_accuracy: 0.9310 - val_loss: 0.2208\n",
      "Epoch 9/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9325 - loss: 0.2150 - val_accuracy: 0.9310 - val_loss: 0.1942\n",
      "Epoch 10/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9642 - loss: 0.1610 - val_accuracy: 0.9310 - val_loss: 0.1726\n",
      "Epoch 11/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9475 - loss: 0.1739 - val_accuracy: 0.9310 - val_loss: 0.1541\n",
      "Epoch 12/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9656 - loss: 0.1548 - val_accuracy: 0.9310 - val_loss: 0.1396\n",
      "Epoch 13/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9563 - loss: 0.1577 - val_accuracy: 0.9310 - val_loss: 0.1256\n",
      "Epoch 14/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9521 - loss: 0.1470 - val_accuracy: 0.9655 - val_loss: 0.1142\n",
      "Epoch 15/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9656 - loss: 0.1260 - val_accuracy: 0.9655 - val_loss: 0.1050\n",
      "Epoch 16/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9625 - loss: 0.1106 - val_accuracy: 0.9655 - val_loss: 0.0974\n",
      "Epoch 17/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9406 - loss: 0.1281 - val_accuracy: 0.9655 - val_loss: 0.0908\n",
      "Epoch 18/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9656 - loss: 0.1048 - val_accuracy: 0.9655 - val_loss: 0.0845\n",
      "Epoch 19/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9556 - loss: 0.1179 - val_accuracy: 0.9655 - val_loss: 0.0791\n",
      "Epoch 20/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9640 - loss: 0.0946 - val_accuracy: 0.9655 - val_loss: 0.0747\n",
      "Epoch 21/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9556 - loss: 0.0969 - val_accuracy: 0.9655 - val_loss: 0.0701\n",
      "Epoch 22/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9692 - loss: 0.0898 - val_accuracy: 0.9655 - val_loss: 0.0660\n",
      "Epoch 23/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9842 - loss: 0.0720 - val_accuracy: 0.9655 - val_loss: 0.0628\n",
      "Epoch 24/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9821 - loss: 0.0751 - val_accuracy: 0.9655 - val_loss: 0.0603\n",
      "Epoch 25/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9763 - loss: 0.0848 - val_accuracy: 0.9655 - val_loss: 0.0582\n",
      "Epoch 26/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9700 - loss: 0.0870 - val_accuracy: 0.9655 - val_loss: 0.0562\n",
      "Epoch 27/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9763 - loss: 0.0726 - val_accuracy: 0.9655 - val_loss: 0.0541\n",
      "Epoch 28/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9763 - loss: 0.0724 - val_accuracy: 0.9655 - val_loss: 0.0516\n",
      "Epoch 29/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9908 - loss: 0.0595 - val_accuracy: 1.0000 - val_loss: 0.0490\n",
      "Epoch 30/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9794 - loss: 0.0588 - val_accuracy: 1.0000 - val_loss: 0.0471\n",
      "Epoch 31/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9877 - loss: 0.0589 - val_accuracy: 1.0000 - val_loss: 0.0452\n",
      "Epoch 32/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9794 - loss: 0.0655 - val_accuracy: 1.0000 - val_loss: 0.0431\n",
      "Epoch 33/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9763 - loss: 0.0575 - val_accuracy: 1.0000 - val_loss: 0.0412\n",
      "Epoch 34/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9763 - loss: 0.0608 - val_accuracy: 1.0000 - val_loss: 0.0397\n",
      "Epoch 35/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9877 - loss: 0.0450 - val_accuracy: 1.0000 - val_loss: 0.0380\n",
      "Epoch 36/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9913 - loss: 0.0575 - val_accuracy: 1.0000 - val_loss: 0.0367\n",
      "Epoch 37/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9913 - loss: 0.0442 - val_accuracy: 1.0000 - val_loss: 0.0356\n",
      "Epoch 38/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0421 - val_accuracy: 1.0000 - val_loss: 0.0346\n",
      "Epoch 39/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0444 - val_accuracy: 1.0000 - val_loss: 0.0331\n",
      "Epoch 40/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0499 - val_accuracy: 1.0000 - val_loss: 0.0322\n",
      "Epoch 41/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0373 - val_accuracy: 1.0000 - val_loss: 0.0310\n",
      "Epoch 42/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0442 - val_accuracy: 1.0000 - val_loss: 0.0295\n",
      "Epoch 43/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0361 - val_accuracy: 1.0000 - val_loss: 0.0281\n",
      "Epoch 44/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0424 - val_accuracy: 1.0000 - val_loss: 0.0272\n",
      "Epoch 45/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0324 - val_accuracy: 1.0000 - val_loss: 0.0265\n",
      "Epoch 46/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0457 - val_accuracy: 1.0000 - val_loss: 0.0265\n",
      "Epoch 47/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0327 - val_accuracy: 1.0000 - val_loss: 0.0262\n",
      "Epoch 48/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0391 - val_accuracy: 1.0000 - val_loss: 0.0256\n",
      "Epoch 49/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0282 - val_accuracy: 1.0000 - val_loss: 0.0248\n",
      "Epoch 50/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0265 - val_accuracy: 1.0000 - val_loss: 0.0238\n"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train_scaled, y_train_onehot, epochs=50, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d3902b-0700-4157-948d-1a76002a49f8",
   "metadata": {},
   "source": [
    "#### 테스트 데이터 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "b4a070e8-033d-4271-b8b0-ef29368d2c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.0112\n",
      "\n",
      "Test Loss: 0.0110\n",
      "Test Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test_onehot)\n",
    "print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1020b477-b8a2-4918-8201-55eac050f29d",
   "metadata": {},
   "source": [
    "#### 예측 수행 및 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "bb771bfa-675a-4bd9-8792-e04780aa3fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x3704784c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/stepWARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x3704784c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_probs = model.predict(X_test_scaled)  # 예측 확률 계산\n",
    "y_pred_classes = np.argmax(y_pred_probs, axis=1)  # 예측된 클래스 인덱스 (가장 확률이 높은 값 선택)\n",
    "y_true_classes = np.argmax(y_test_onehot, axis=1)  # 실제 클래스 인덱스"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de95a2e5-e7f8-4e28-834e-6f92ccc6dba8",
   "metadata": {},
   "source": [
    "#### 성능지표(f1_score, precision, recall) 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "3394dc5f-031d-4690-b3f9-4af64b9b420a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CNN 성능 지표 ===\n",
      "F1 Score: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_true_classes, y_pred_classes, average='macro')\n",
    "precision = precision_score(y_true_classes, y_pred_classes, average='macro')\n",
    "recall = recall_score(y_true_classes, y_pred_classes, average='macro')\n",
    "\n",
    "print(\"\\n=== CNN 성능 지표 ===\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b7a510-82b3-42c1-b0b5-044026fd1f0a",
   "metadata": {},
   "source": [
    "#### 혼동 행렬 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "51d28361-958a-433d-85bf-0f875226fdce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[14  0  0]\n",
      " [ 0 14  0]\n",
      " [ 0  0  8]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd15fa32-ce78-4af2-abe5-0efc8c5e5db8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
