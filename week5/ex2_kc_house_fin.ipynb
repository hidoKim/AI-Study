{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c039877b-d086-46f5-8d4e-d5cedacaeb54",
   "metadata": {},
   "source": [
    "## kc_house 예제 (MLP 딥러닝 회귀)\n",
    "\n",
    "딥러닝 회귀 : MSE지표 필수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bc3c9fb0-d0c8-4116-91f8-7355b78916e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b29277c-f090-4a7d-8e52-15223025e0fc",
   "metadata": {},
   "source": [
    "### 데이터 로드 및 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e495bf53-287c-43bb-8ad9-5a2afb0612cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21608</th>\n",
       "      <td>263000018</td>\n",
       "      <td>20140521T000000</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1530</td>\n",
       "      <td>1131</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1530</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98103</td>\n",
       "      <td>47.6993</td>\n",
       "      <td>-122.346</td>\n",
       "      <td>1530</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21609</th>\n",
       "      <td>6600060120</td>\n",
       "      <td>20150223T000000</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2310</td>\n",
       "      <td>5813</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2310</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>98146</td>\n",
       "      <td>47.5107</td>\n",
       "      <td>-122.362</td>\n",
       "      <td>1830</td>\n",
       "      <td>7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21610</th>\n",
       "      <td>1523300141</td>\n",
       "      <td>20140623T000000</td>\n",
       "      <td>402101.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1350</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5944</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21611</th>\n",
       "      <td>291310100</td>\n",
       "      <td>20150116T000000</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1600</td>\n",
       "      <td>2388</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>98027</td>\n",
       "      <td>47.5345</td>\n",
       "      <td>-122.069</td>\n",
       "      <td>1410</td>\n",
       "      <td>1287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21612</th>\n",
       "      <td>1523300157</td>\n",
       "      <td>20141015T000000</td>\n",
       "      <td>325000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1076</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5941</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21613 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id             date     price  bedrooms  bathrooms  \\\n",
       "0      7129300520  20141013T000000  221900.0         3       1.00   \n",
       "1      6414100192  20141209T000000  538000.0         3       2.25   \n",
       "2      5631500400  20150225T000000  180000.0         2       1.00   \n",
       "3      2487200875  20141209T000000  604000.0         4       3.00   \n",
       "4      1954400510  20150218T000000  510000.0         3       2.00   \n",
       "...           ...              ...       ...       ...        ...   \n",
       "21608   263000018  20140521T000000  360000.0         3       2.50   \n",
       "21609  6600060120  20150223T000000  400000.0         4       2.50   \n",
       "21610  1523300141  20140623T000000  402101.0         2       0.75   \n",
       "21611   291310100  20150116T000000  400000.0         3       2.50   \n",
       "21612  1523300157  20141015T000000  325000.0         2       0.75   \n",
       "\n",
       "       sqft_living  sqft_lot  floors  waterfront  view  ...  grade  \\\n",
       "0             1180      5650     1.0           0     0  ...      7   \n",
       "1             2570      7242     2.0           0     0  ...      7   \n",
       "2              770     10000     1.0           0     0  ...      6   \n",
       "3             1960      5000     1.0           0     0  ...      7   \n",
       "4             1680      8080     1.0           0     0  ...      8   \n",
       "...            ...       ...     ...         ...   ...  ...    ...   \n",
       "21608         1530      1131     3.0           0     0  ...      8   \n",
       "21609         2310      5813     2.0           0     0  ...      8   \n",
       "21610         1020      1350     2.0           0     0  ...      7   \n",
       "21611         1600      2388     2.0           0     0  ...      8   \n",
       "21612         1020      1076     2.0           0     0  ...      7   \n",
       "\n",
       "       sqft_above  sqft_basement  yr_built  yr_renovated  zipcode      lat  \\\n",
       "0            1180              0      1955             0    98178  47.5112   \n",
       "1            2170            400      1951          1991    98125  47.7210   \n",
       "2             770              0      1933             0    98028  47.7379   \n",
       "3            1050            910      1965             0    98136  47.5208   \n",
       "4            1680              0      1987             0    98074  47.6168   \n",
       "...           ...            ...       ...           ...      ...      ...   \n",
       "21608        1530              0      2009             0    98103  47.6993   \n",
       "21609        2310              0      2014             0    98146  47.5107   \n",
       "21610        1020              0      2009             0    98144  47.5944   \n",
       "21611        1600              0      2004             0    98027  47.5345   \n",
       "21612        1020              0      2008             0    98144  47.5941   \n",
       "\n",
       "          long  sqft_living15  sqft_lot15  \n",
       "0     -122.257           1340        5650  \n",
       "1     -122.319           1690        7639  \n",
       "2     -122.233           2720        8062  \n",
       "3     -122.393           1360        5000  \n",
       "4     -122.045           1800        7503  \n",
       "...        ...            ...         ...  \n",
       "21608 -122.346           1530        1509  \n",
       "21609 -122.362           1830        7200  \n",
       "21610 -122.299           1020        2007  \n",
       "21611 -122.069           1410        1287  \n",
       "21612 -122.299           1020        1357  \n",
       "\n",
       "[21613 rows x 21 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = './kc_house_data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "97e3748e-5334-4c0c-b375-e55d2bb883e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 shape: (21613, 21)\n",
      "\n",
      "컬럼 정보:\n",
      " Index(['id', 'date', 'price', 'bedrooms', 'bathrooms', 'sqft_living',\n",
      "       'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
      "       'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n",
      "       'lat', 'long', 'sqft_living15', 'sqft_lot15'],\n",
      "      dtype='object')\n",
      "=== 결측치 현황 ===\n",
      "id               0\n",
      "date             0\n",
      "price            0\n",
      "bedrooms         0\n",
      "bathrooms        0\n",
      "sqft_living      0\n",
      "sqft_lot         0\n",
      "floors           0\n",
      "waterfront       0\n",
      "view             0\n",
      "condition        0\n",
      "grade            0\n",
      "sqft_above       0\n",
      "sqft_basement    0\n",
      "yr_built         0\n",
      "yr_renovated     0\n",
      "zipcode          0\n",
      "lat              0\n",
      "long             0\n",
      "sqft_living15    0\n",
      "sqft_lot15       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "print(\"데이터 shape:\", df.shape)\n",
    "print(\"\\n컬럼 정보:\\n\", df.columns)\n",
    "\n",
    "# 결측치 확인\n",
    "print(\"=== 결측치 현황 ===\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aae25574-bdac-43ed-9720-084e9b5558b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== 레이블 분포 ====\n",
      "price\n",
      "350000.0     172\n",
      "450000.0     172\n",
      "550000.0     159\n",
      "500000.0     152\n",
      "425000.0     150\n",
      "            ... \n",
      "607010.0       1\n",
      "1362500.0      1\n",
      "298800.0       1\n",
      "957500.0       1\n",
      "402101.0       1\n",
      "Name: count, Length: 4028, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#레이블 분포 확인\n",
    "print(\"\\n==== 레이블 분포 ====\")\n",
    "print(df['price'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3a2b81-b901-4cec-b0ca-b143a1cd2a2f",
   "metadata": {},
   "source": [
    "### 데이터 전처리\n",
    "#### 불필요한 컬럼 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "877ca6fd-1058-405d-a377-db8af3c0c017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors',\n",
      "       'waterfront', 'view', 'condition', 'grade', 'sqft_above',\n",
      "       'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long',\n",
      "       'sqft_living15', 'sqft_lot15'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['id', 'date'], axis=1) # axis=1: 열(columns)을 기준으로 작업\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcbb98d-9394-4b2e-b5d0-9a33094ed7ce",
   "metadata": {},
   "source": [
    "#### 타겟 변수 로그 변환 (가격 분포 정규화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0e19cf8c-18a8-4f87-84cd-0b2b2d91b3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price_log'] = np.log1p(df['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2d0ce0-b442-4230-83f9-6cbb46af56e1",
   "metadata": {},
   "source": [
    "#### 특성과 타겟(레이블 분리)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "49d725d4-db31-4230-94e3-3ffc1ccdcd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['price', 'price_log'], axis=1)\n",
    "y = df['price_log']  # 로그 변환된 가격 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0898b578-e3fb-42ae-84ac-c0188b078642",
   "metadata": {},
   "source": [
    "#### 훈련 및 테스트 세트 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cf4b02cb-46a2-4444-a882-025c0e3f4a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "832ede10-939a-4eb9-8a82-6cfac9bf5f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 스케일링 (회귀는 원-핫 엔코딩이 필요 없음)\n",
    "scaler_X = StandardScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "627bcb7d-95fb-4522-84e7-9c2ca5eade12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 데이터셋 Shape ===\n",
      "X_train_scaled shape: (17290, 18)\n",
      "X_test_scaled shape: (4323, 18)\n",
      "y_train shape: (17290,)\n",
      "y_test shape: (4323,)\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 Shape 확인\n",
    "print(\"\\n=== 데이터셋 Shape ===\")\n",
    "print(\"X_train_scaled shape:\", X_train_scaled.shape)\n",
    "print(\"X_test_scaled shape:\", X_test_scaled.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da93236-b499-4a06-a9c6-46536693cb99",
   "metadata": {},
   "source": [
    "### 5가지 분류 (RF, DT, LR, KNN, SVM) 하고, RMSE 및 R² 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d246a604-13aa-49e6-8bcc-3d66355e2a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 머신러닝 모델 성능 ===\n",
      "\n",
      "SVM:\n",
      "RMSE: 184,106 달러\n",
      "MAE: 84,188 달러\n",
      "R²: 0.7758\n",
      "\n",
      "Decision Tree:\n",
      "RMSE: 187,468 달러\n",
      "MAE: 101,570 달러\n",
      "R²: 0.7675\n",
      "\n",
      "Random Forest:\n",
      "RMSE: 136,057 달러\n",
      "MAE: 71,894 달러\n",
      "R²: 0.8775\n",
      "\n",
      "Linear Regression:\n",
      "RMSE: 275,303 달러\n",
      "MAE: 117,259 달러\n",
      "R²: 0.4987\n",
      "\n",
      "KNN:\n",
      "RMSE: 182,232 달러\n",
      "MAE: 92,274 달러\n",
      "R²: 0.7803\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"SVM\": SVR(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"KNN\": KNeighborsRegressor()\n",
    "}\n",
    "\n",
    "print(\"=== 머신러닝 모델 성능 ===\")\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train) # 모델 학습\n",
    "    y_pred = model.predict(X_test_scaled) # 테스트 데이터 예측\n",
    "    \n",
    "    # 지수 변환으로 원래 가격 복원 (로그 변환된 값을 되돌림)\n",
    "    y_pred_orig = np.expm1(y_pred)\n",
    "    y_test_orig = np.expm1(y_test)\n",
    "\n",
    "    # 성능지표 계산\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_orig, y_pred_orig))\n",
    "    mae = mean_absolute_error(y_test_orig, y_pred_orig)\n",
    "    r2 = r2_score(y_test_orig, y_pred_orig)\n",
    "\n",
    "    # 결과 출력\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"RMSE: {rmse:,.0f} 달러\")\n",
    "    print(f\"MAE: {mae:,.0f} 달러\")\n",
    "    print(f\"R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebe934c-c6f9-4938-bd66-7bd3bbfd1fec",
   "metadata": {},
   "source": [
    "### MLP 딥러닝 (텐서플로우)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "84be1b62-cf70-49d7-bffc-931c20435a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimdoyeon/Projects/SchoolProjects/AI-Study/week4/.venv/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 112.6130 - mae: 9.7741 - val_loss: 3.7505 - val_mae: 1.5852\n",
      "Epoch 2/50\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 17.2495 - mae: 3.0439 - val_loss: 5.4301 - val_mae: 1.8040\n",
      "Epoch 3/50\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 12.7987 - mae: 2.6925 - val_loss: 1.6603 - val_mae: 1.1309\n",
      "Epoch 4/50\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 2.1876 - mae: 1.1168 - val_loss: 0.2194 - val_mae: 0.3669\n",
      "Epoch 5/50\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2528 - mae: 0.3789 - val_loss: 0.0728 - val_mae: 0.2102\n",
      "Epoch 6/50\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.1920 - mae: 0.3317 - val_loss: 0.0980 - val_mae: 0.2447\n",
      "Epoch 7/50\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.2311 - mae: 0.3623 - val_loss: 1.0449 - val_mae: 0.8594\n",
      "Epoch 8/50\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.2313 - mae: 0.3622 - val_loss: 0.1320 - val_mae: 0.2840\n",
      "Epoch 9/50\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.2621 - mae: 0.3892 - val_loss: 0.2238 - val_mae: 0.3640\n",
      "Epoch 10/50\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.2992 - mae: 0.4058 - val_loss: 0.1032 - val_mae: 0.2518\n",
      "Epoch 11/50\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.2381 - mae: 0.3680 - val_loss: 0.1336 - val_mae: 0.2767\n",
      "Epoch 12/50\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.5031 - mae: 0.5048 - val_loss: 0.0706 - val_mae: 0.2038\n",
      "Epoch 13/50\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.5842 - mae: 0.5044 - val_loss: 0.1875 - val_mae: 0.3403\n",
      "Epoch 14/50\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.2887 - mae: 0.3786 - val_loss: 0.1202 - val_mae: 0.2616\n",
      "Epoch 15/50\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.2204 - mae: 0.3449 - val_loss: 0.1866 - val_mae: 0.3385\n",
      "Epoch 16/50\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.3192 - mae: 0.4030 - val_loss: 0.1000 - val_mae: 0.2466\n",
      "Epoch 17/50\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.4975 - mae: 0.4833 - val_loss: 0.0783 - val_mae: 0.2196\n",
      "Epoch 18/50\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.5632 - mae: 0.5168 - val_loss: 0.4112 - val_mae: 0.4817\n",
      "Epoch 19/50\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.4370 - mae: 0.4725 - val_loss: 1.4829 - val_mae: 0.8888\n",
      "Epoch 20/50\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.8362 - mae: 0.6255 - val_loss: 0.1067 - val_mae: 0.2455\n",
      "Epoch 21/50\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.3157 - mae: 0.4006 - val_loss: 0.3541 - val_mae: 0.4384\n",
      "Epoch 22/50\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.6010 - mae: 0.5326 - val_loss: 1.5908 - val_mae: 0.9402\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "=== 딥러닝 모델 (TensorFlow) ===\n",
      "RMSE: 260,025 달러\n",
      "MAE: 121,062 달러\n",
      "R²: 0.5528\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError  # MSE 손실 함수 사용\n",
    "\n",
    "# 모델 구조 정의\n",
    "\n",
    "# 모델 구조 정의 (배치 정규화 및 드롭아웃 추가)\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    BatchNormalization(),  # 배치 정규화 추가\n",
    "    Dropout(0.3),          # 드롭아웃 추가\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # 출력층\n",
    "])\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001) # 학습률\n",
    "\n",
    "# 모델 컴파일 (회귀 설정)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='mse',  # 평균 제곱 오차\n",
    "    metrics=['mae']  # 평균 절대 오차\n",
    ")\n",
    "\n",
    "# 조기 종료 콜백 추가\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2, #X_train_scaled의 20%를 검증 데이터로 분리\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],  # 조기 종료 적용  \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 테스트 평가 및 결과 복원\n",
    "y_pred_log = model.predict(X_test_scaled).flatten()\n",
    "y_pred_orig = np.expm1(y_pred_log)  # 로그 변환 복원\n",
    "y_test_orig = np.expm1(y_test)  # 실제 값 복원\n",
    "\n",
    "# 성능 지표 계산\n",
    "rmse = np.sqrt(mean_squared_error(y_test_orig, y_pred_orig))\n",
    "mae = mean_absolute_error(y_test_orig, y_pred_orig)\n",
    "r2 = r2_score(y_test_orig, y_pred_orig)\n",
    "\n",
    "print(\"\\n=== 딥러닝 모델 (TensorFlow) ===\")\n",
    "print(f\"RMSE: {rmse:,.0f} 달러\")\n",
    "print(f\"MAE: {mae:,.0f} 달러\")\n",
    "print(f\"R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f6103ca1-6ea1-40d4-b691-e8df8846470d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 34\n",
      "\n",
      "=== 딥러닝 모델 성능 ===\n",
      "RMSE: 258,990 달러\n",
      "MAE: 103,407 달러\n",
      "R²: 0.5563\n"
     ]
    }
   ],
   "source": [
    "# # PyTorch 회귀 모델\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# # 데이터 텐서 변환\n",
    "# X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)  # 수정: X_train_scaled 사용\n",
    "# y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "# X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)  # 스케일링된 데이터 사용\n",
    "\n",
    "# # 신경망 정의\n",
    "# # 모델 구조 개선\n",
    "# class EnhancedHousePricePredictor(nn.Module):\n",
    "#     def __init__(self, input_dim):\n",
    "#         super().__init__()\n",
    "#         self.fc1 = nn.Linear(input_dim, 256)  # 은닉층 뉴런 수 증가\n",
    "#         self.bn1 = nn.BatchNorm1d(256)       # 배치 정규화 추가\n",
    "#         self.dropout = nn.Dropout(0.3)       # 드롭아웃 추가 (과적합 방지)\n",
    "#         self.fc2 = nn.Linear(256, 128)\n",
    "#         self.fc3 = nn.Linear(128, 64)\n",
    "#         self.fc4 = nn.Linear(64, 1)          # 출력층 (회귀: 출력값 1개)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = torch.relu(self.bn1(self.fc1(x)))\n",
    "#         x = self.dropout(x)\n",
    "#         x = torch.relu(self.fc2(x))\n",
    "#         x = torch.relu(self.fc3(x))\n",
    "#         return self.fc4(x)\n",
    "        \n",
    "# # 모델 설정\n",
    "# model = EnhancedHousePricePredictor(input_dim=X_train.shape[1])\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# X_train_sub, X_val_sub, y_train_sub, y_val_sub = train_test_split(\n",
    "#     X_train_scaled, y_train, \n",
    "#     test_size=0.2, \n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# # DataLoader\n",
    "# train_dataset = TensorDataset(\n",
    "#     torch.tensor(X_train_sub, dtype=torch.float32),\n",
    "#     torch.tensor(y_train_sub.values, dtype=torch.float32).view(-1, 1)\n",
    "# )\n",
    "# val_dataset = TensorDataset(\n",
    "#     torch.tensor(X_val_sub, dtype=torch.float32),\n",
    "#     torch.tensor(y_val_sub.values, dtype=torch.float32).view(-1, 1)\n",
    "# )\n",
    "# train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=64)\n",
    "\n",
    "# # 학습 루프 (조기 종료 추가)\n",
    "# num_epochs = 500\n",
    "# best_val_loss = float('inf')\n",
    "# patience = 10\n",
    "# patience_counter = 0\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     train_loss = 0.0\n",
    "#     for inputs, labels in train_loader:\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         train_loss += loss.item()\n",
    "    \n",
    "#     # 검증 손실 계산\n",
    "#     model.eval()\n",
    "#     val_loss = 0.0\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, labels in val_loader:\n",
    "#             outputs = model(inputs)\n",
    "#             val_loss += criterion(outputs, labels).item()\n",
    "    \n",
    "#     train_loss /= len(train_loader)\n",
    "#     val_loss /= len(val_loader)\n",
    "    \n",
    "#     # 조기 종료\n",
    "#     if val_loss < best_val_loss:\n",
    "#         best_val_loss = val_loss\n",
    "#         patience_counter = 0\n",
    "#         torch.save(model.state_dict(), 'best_model.pth')  # 최적 모델 저장\n",
    "#     else:\n",
    "#         patience_counter += 1\n",
    "#         if patience_counter >= patience:\n",
    "#             print(f\"Early stopping at epoch {epoch+1}\")\n",
    "#             break\n",
    "    \n",
    "#     # 50에포크마다 결과 출력\n",
    "#     if (epoch+1) % 50 == 0:\n",
    "#         print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "# # 최적 모델 로드\n",
    "# model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# # 테스트 평가\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     y_pred_log = model(X_test_tensor).numpy().flatten()\n",
    "\n",
    "# # 결과 복원 및 평가\n",
    "# y_pred_orig = np.expm1(y_pred_log)\n",
    "# y_test_orig = np.expm1(y_test)\n",
    "\n",
    "# print(\"\\n=== 딥러닝 모델 성능 ===\")\n",
    "# print(f\"RMSE: {np.sqrt(mean_squared_error(y_test_orig, y_pred_orig)):,.0f} 달러\")\n",
    "# print(f\"MAE: {mean_absolute_error(y_test_orig, y_pred_orig):,.0f} 달러\")\n",
    "# print(f\"R²: {r2_score(y_test_orig, y_pred_orig):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4f7b4e-dda1-4d92-9b5e-5b4d6877c295",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
