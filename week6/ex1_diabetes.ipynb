{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c410054b-7bc6-467b-b027-5b1ebf5ccf9f",
   "metadata": {},
   "source": [
    "## diabetes 예제 딥러닝 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f8e93bf-4737-42e9-83f2-a5cea2596429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import kerastuner as kt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93dd5a79-03f0-47a5-9a18-a1802e104637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = './diabetes.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f538b03-d6c4-4d07-ba57-32262e4a15ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 형태: (768, 9)\n",
      "\n",
      "컬럼 정보:\n",
      " Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
      "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
      "      dtype='object')\n",
      "\n",
      "클래스 분포:\n",
      " Outcome\n",
      "0    500\n",
      "1    268\n",
      "Name: count, dtype: int64\n",
      "=== 결측치 현황 ===\n",
      "Pregnancies                 0\n",
      "Glucose                     0\n",
      "BloodPressure               0\n",
      "SkinThickness               0\n",
      "Insulin                     0\n",
      "BMI                         0\n",
      "DiabetesPedigreeFunction    0\n",
      "Age                         0\n",
      "Outcome                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "print(\"데이터 형태:\", data.shape)\n",
    "print(\"\\n컬럼 정보:\\n\", data.columns)\n",
    "print(\"\\n클래스 분포:\\n\", data[\"Outcome\"].value_counts())\n",
    "\n",
    "# 결측치 확인\n",
    "print(\"=== 결측치 현황 ===\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b8aa2a96-a761-46ef-890d-43cfe5be72dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 레이블 분포 ===\n",
      "Outcome\n",
      "0    500\n",
      "1    268\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 레이블 분포 확인\n",
    "print(\"\\n=== 레이블 분포 ===\")\n",
    "print(data['Outcome'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "88da7c97-ca69-469c-ac25-a9006ebdaa9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 데이터셋 Shape ===\n",
      "X_train shape: (614, 8)\n",
      "X_test shape: (154, 8)\n",
      "y_train shape: (614,)\n",
      "y_test shape: (154,)\n"
     ]
    }
   ],
   "source": [
    "# 특성(X)과 레이블(y) 분리\n",
    "X = data.drop(\"Outcome\", axis=1)\n",
    "y = data[\"Outcome\"]\n",
    "\n",
    "# 훈련/테스트 세트 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 데이터셋 Shape 확인\n",
    "print(\"\\n=== 데이터셋 Shape ===\")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ce4ce59e-4e69-42cf-aa74-c64ae5f90f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 모델 성능 비교 ===\n",
      "\n",
      "=======Random Forest=======\n",
      "Accuracy: 0.7273\n",
      "f1_score: 0.6181818181818182\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79        99\n",
      "           1       0.62      0.62      0.62        55\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.70      0.70      0.70       154\n",
      "weighted avg       0.73      0.73      0.73       154\n",
      "\n",
      "Confusion Matrix:\n",
      "[[78 21]\n",
      " [21 34]]\n",
      "\n",
      "=======Decision Tree=======\n",
      "Accuracy: 0.7532\n",
      "f1_score: 0.6607142857142857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81        99\n",
      "           1       0.65      0.67      0.66        55\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.74      0.73       154\n",
      "weighted avg       0.76      0.75      0.75       154\n",
      "\n",
      "Confusion Matrix:\n",
      "[[79 20]\n",
      " [18 37]]\n",
      "\n",
      "=======Logistic Regression=======\n",
      "Accuracy: 0.7468\n",
      "f1_score: 0.6548672566371682\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80        99\n",
      "           1       0.64      0.67      0.65        55\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.73      0.73       154\n",
      "weighted avg       0.75      0.75      0.75       154\n",
      "\n",
      "Confusion Matrix:\n",
      "[[78 21]\n",
      " [18 37]]\n",
      "\n",
      "=======KNN=======\n",
      "Accuracy: 0.6623\n",
      "f1_score: 0.5517241379310345\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.71      0.73        99\n",
      "           1       0.52      0.58      0.55        55\n",
      "\n",
      "    accuracy                           0.66       154\n",
      "   macro avg       0.64      0.64      0.64       154\n",
      "weighted avg       0.67      0.66      0.67       154\n",
      "\n",
      "Confusion Matrix:\n",
      "[[70 29]\n",
      " [23 32]]\n",
      "\n",
      "=======SVM=======\n",
      "Accuracy: 0.7662\n",
      "f1_score: 0.6326530612244898\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.83        99\n",
      "           1       0.72      0.56      0.63        55\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.75      0.72      0.73       154\n",
      "weighted avg       0.76      0.77      0.76       154\n",
      "\n",
      "Confusion Matrix:\n",
      "[[87 12]\n",
      " [24 31]]\n"
     ]
    }
   ],
   "source": [
    "# 분류기 초기화\n",
    "classifiers = {\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'SVM': SVC()\n",
    "}\n",
    "\n",
    "# 모델 학습 및 평가\n",
    "results = []\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train) # 모델 학습\n",
    "    y_pred = clf.predict(X_test) # 테스트 데이터 예측\n",
    "    acc = accuracy_score(y_test, y_pred) # 정확도 계산\n",
    "    cm = confusion_matrix(y_test, y_pred) # 혼동 행렬 계산 (TP|FN|FP|TN)\n",
    "    cr = classification_report(y_test, y_pred) # 분류 보고서\n",
    "    f1 = f1_score(y_test, y_pred) # f1값 계산\n",
    "    results.append((name, acc, cm, cr, f1)) # 결과를 리스트에 저장\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n=== 모델 성능 비교 ===\")\n",
    "for name, acc, cm, cr, f1 in results:\n",
    "    print(f\"\\n======={name}=======\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"f1_score: {f1}\")\n",
    "    print(cr)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3e62196d-a28c-4072-9c98-013ee9b73aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 데이터셋 Shape ===\n",
      "X_train_scaled shape: (614, 8)\n",
      "X_test_scaled shape: (154, 8)\n",
      "y_train shape: (614,)\n",
      "y_test shape: (154,)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # 훈련 데이터로 학습\n",
    "X_test_scaled = scaler.transform(X_test)        # 테스트 데이터 변환\n",
    "\n",
    "# 데이터셋 Shape 확인\n",
    "print(\"\\n=== 데이터셋 Shape ===\")\n",
    "print(\"X_train_scaled shape:\", X_train_scaled.shape)\n",
    "print(\"X_test_scaled shape:\", X_test_scaled.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fd2e25-4406-4925-a43c-cd5186c76349",
   "metadata": {},
   "source": [
    "### 텐서플로우로 딥러닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d51f0a32-3b36-4fbe-8bd4-6c92324202e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimdoyeon/Projects/SchoolProjects/AI-Study/week4/.venv/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7347 - loss: 0.5418 - val_accuracy: 0.7805 - val_loss: 0.5300\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7493 - loss: 0.5211 - val_accuracy: 0.7805 - val_loss: 0.4967\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7665 - loss: 0.4903 - val_accuracy: 0.7642 - val_loss: 0.4776\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7657 - loss: 0.4790 - val_accuracy: 0.7642 - val_loss: 0.4713\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7813 - loss: 0.4598 - val_accuracy: 0.7642 - val_loss: 0.4740\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7758 - loss: 0.4831 - val_accuracy: 0.7561 - val_loss: 0.4742\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7757 - loss: 0.4737 - val_accuracy: 0.7561 - val_loss: 0.4709\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7711 - loss: 0.4940 - val_accuracy: 0.7317 - val_loss: 0.4716\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7680 - loss: 0.4749 - val_accuracy: 0.7480 - val_loss: 0.4708\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7680 - loss: 0.4691 - val_accuracy: 0.7724 - val_loss: 0.4664\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7641 - loss: 0.4856 - val_accuracy: 0.7724 - val_loss: 0.4666\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7728 - loss: 0.4617 - val_accuracy: 0.7805 - val_loss: 0.4617\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7653 - loss: 0.4668 - val_accuracy: 0.7805 - val_loss: 0.4650\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7648 - loss: 0.4832 - val_accuracy: 0.7805 - val_loss: 0.4652\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7715 - loss: 0.4863 - val_accuracy: 0.7642 - val_loss: 0.4659\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7835 - loss: 0.4609 - val_accuracy: 0.7886 - val_loss: 0.4674\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7738 - loss: 0.4805 - val_accuracy: 0.7642 - val_loss: 0.4658\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7954 - loss: 0.4494 - val_accuracy: 0.7886 - val_loss: 0.4652\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7532 - loss: 0.4969 - val_accuracy: 0.7886 - val_loss: 0.4652\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7542 - loss: 0.4877 - val_accuracy: 0.7642 - val_loss: 0.4666\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7927 - loss: 0.4596 - val_accuracy: 0.7886 - val_loss: 0.4657\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7800 - loss: 0.4368 - val_accuracy: 0.7805 - val_loss: 0.4644\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7676 - loss: 0.4698 - val_accuracy: 0.7805 - val_loss: 0.4672\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7558 - loss: 0.4837 - val_accuracy: 0.7642 - val_loss: 0.4691\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7735 - loss: 0.4625 - val_accuracy: 0.7398 - val_loss: 0.4680\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7801 - loss: 0.4587 - val_accuracy: 0.7561 - val_loss: 0.4697\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7522 - loss: 0.4978 - val_accuracy: 0.7886 - val_loss: 0.4658\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7677 - loss: 0.4858 - val_accuracy: 0.7805 - val_loss: 0.4649\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7712 - loss: 0.4619 - val_accuracy: 0.7886 - val_loss: 0.4635\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7796 - loss: 0.4754 - val_accuracy: 0.7480 - val_loss: 0.4638\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7818 - loss: 0.4708 - val_accuracy: 0.7886 - val_loss: 0.4639\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7598 - loss: 0.4624 - val_accuracy: 0.7805 - val_loss: 0.4666\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7729 - loss: 0.4744 - val_accuracy: 0.7561 - val_loss: 0.4742\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7515 - loss: 0.5069 - val_accuracy: 0.7398 - val_loss: 0.4797\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7851 - loss: 0.4658 - val_accuracy: 0.7561 - val_loss: 0.4758\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7608 - loss: 0.4869 - val_accuracy: 0.7480 - val_loss: 0.4707\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7729 - loss: 0.4682 - val_accuracy: 0.7886 - val_loss: 0.4702\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7588 - loss: 0.5036 - val_accuracy: 0.7642 - val_loss: 0.4662\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7849 - loss: 0.4513 - val_accuracy: 0.7805 - val_loss: 0.4708\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7919 - loss: 0.4702 - val_accuracy: 0.7561 - val_loss: 0.4736\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7515 - loss: 0.4904 - val_accuracy: 0.7317 - val_loss: 0.4888\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7548 - loss: 0.4979 - val_accuracy: 0.7642 - val_loss: 0.4672\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7457 - loss: 0.4907 - val_accuracy: 0.7561 - val_loss: 0.4748\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7640 - loss: 0.4724 - val_accuracy: 0.7480 - val_loss: 0.4732\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7639 - loss: 0.4700 - val_accuracy: 0.7561 - val_loss: 0.4953\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7644 - loss: 0.5053 - val_accuracy: 0.7398 - val_loss: 0.4754\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7624 - loss: 0.4795 - val_accuracy: 0.7317 - val_loss: 0.4872\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7944 - loss: 0.4521 - val_accuracy: 0.7642 - val_loss: 0.4681\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7650 - loss: 0.4690 - val_accuracy: 0.7561 - val_loss: 0.4930\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7616 - loss: 0.4866 - val_accuracy: 0.7724 - val_loss: 0.4646\n"
     ]
    }
   ],
   "source": [
    "# MLP 신경망 정의\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),  # 입력층 → 은닉층1 (64개 뉴런)\n",
    "    Dense(32, activation='relu'),  # 은닉층1 → 은닉층2 (32개 뉴런)\n",
    "    Dense(1, activation='sigmoid')  # 출력층 (시그모이드 활성화)\n",
    "])\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),  # Adam 옵티마이저 (학습률 0.001)\n",
    "    loss='binary_crossentropy',  # 이진 교차 엔트로피 손실\n",
    "    metrics=['accuracy']  # 정확도 추적\n",
    ")\n",
    "\n",
    "# 검증 세트 분리 (훈련 데이터의 20%)\n",
    "X_train_sub, X_val, y_train_sub, y_val = train_test_split(\n",
    "    X_train_scaled, y_train, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 학습 (배치 크기 32, 50 에포크)\n",
    "history = model.fit(\n",
    "    X_train_sub, y_train_sub,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    verbose=1  # 학습 과정 출력\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "83ed18c7-21a0-44c1-8c87-6a414e6e5572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x36b5d7820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/stepWARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x36b5d7820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\n",
      "=== 딥러닝 모델 (TensorFlow) ===\n",
      "F1 Score: 0.6486\n",
      "정확도: 0.7468\n",
      "Confusion Matrix:\n",
      "[[79 20]\n",
      " [19 36]]\n"
     ]
    }
   ],
   "source": [
    "# 테스트 평가\n",
    "test_loss, test_acc = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "y_pred_proba = model.predict(X_test_scaled)  # 확률 예측\n",
    "y_pred_dl = (y_pred_proba > 0.5).astype(int).flatten()  # 0.5 기준 이진 분류\n",
    "\n",
    "# 성능 지표 계산\n",
    "f1_dl = f1_score(y_test, y_pred_dl)\n",
    "print(\"\\n=== 딥러닝 모델 (TensorFlow) ===\")\n",
    "print(f\"F1 Score: {f1_dl:.4f}\")\n",
    "print(f\"정확도: {test_acc:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2e9711-a41c-46e9-adf3-09a2e7b06b5c",
   "metadata": {},
   "source": [
    "### 파이토치로 딥러닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "50535652-1f7b-4c2c-868e-887f9a7fd6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== pytorch 데이터셋 Shape ===\n",
      "X_train_sub_tensor shape: torch.Size([491, 8])\n",
      "y_train_sub_tensor shape: torch.Size([491, 1])\n",
      "X_val_tensor shape: torch.Size([123, 8])\n",
      "y_val_tensor shape: torch.Size([123, 1])\n",
      "X_test_tensor shape: torch.Size([154, 8])\n",
      "y_test_tensor shape: torch.Size([154, 1])\n",
      "\n",
      "\n",
      "Epoch 1/50 | Train Loss: 0.6788 | Val Loss: 0.6539 | Val Acc: 0.6585\n",
      "Epoch 2/50 | Train Loss: 0.6234 | Val Loss: 0.6013 | Val Acc: 0.6829\n",
      "Epoch 3/50 | Train Loss: 0.5718 | Val Loss: 0.5619 | Val Acc: 0.6748\n",
      "Epoch 4/50 | Train Loss: 0.5445 | Val Loss: 0.5307 | Val Acc: 0.7236\n",
      "Epoch 5/50 | Train Loss: 0.5119 | Val Loss: 0.5098 | Val Acc: 0.7480\n",
      "Epoch 6/50 | Train Loss: 0.4981 | Val Loss: 0.4904 | Val Acc: 0.7480\n",
      "Epoch 7/50 | Train Loss: 0.4819 | Val Loss: 0.4770 | Val Acc: 0.7480\n",
      "Epoch 8/50 | Train Loss: 0.4686 | Val Loss: 0.4669 | Val Acc: 0.7805\n",
      "Epoch 9/50 | Train Loss: 0.4646 | Val Loss: 0.4605 | Val Acc: 0.7967\n",
      "Epoch 10/50 | Train Loss: 0.4630 | Val Loss: 0.4558 | Val Acc: 0.8211\n",
      "Epoch 11/50 | Train Loss: 0.4510 | Val Loss: 0.4529 | Val Acc: 0.8049\n",
      "Epoch 12/50 | Train Loss: 0.4490 | Val Loss: 0.4521 | Val Acc: 0.8049\n",
      "Epoch 13/50 | Train Loss: 0.4363 | Val Loss: 0.4504 | Val Acc: 0.7967\n",
      "Epoch 14/50 | Train Loss: 0.4388 | Val Loss: 0.4498 | Val Acc: 0.7886\n",
      "Epoch 15/50 | Train Loss: 0.4389 | Val Loss: 0.4449 | Val Acc: 0.7886\n",
      "Epoch 16/50 | Train Loss: 0.4334 | Val Loss: 0.4476 | Val Acc: 0.7805\n",
      "Epoch 17/50 | Train Loss: 0.4248 | Val Loss: 0.4460 | Val Acc: 0.7886\n",
      "Epoch 18/50 | Train Loss: 0.4308 | Val Loss: 0.4445 | Val Acc: 0.7805\n",
      "Epoch 19/50 | Train Loss: 0.4346 | Val Loss: 0.4469 | Val Acc: 0.7805\n",
      "Epoch 20/50 | Train Loss: 0.4184 | Val Loss: 0.4420 | Val Acc: 0.7642\n",
      "Epoch 21/50 | Train Loss: 0.4184 | Val Loss: 0.4423 | Val Acc: 0.7805\n",
      "Epoch 22/50 | Train Loss: 0.4154 | Val Loss: 0.4475 | Val Acc: 0.7642\n",
      "Epoch 23/50 | Train Loss: 0.4163 | Val Loss: 0.4512 | Val Acc: 0.7724\n",
      "Epoch 24/50 | Train Loss: 0.4108 | Val Loss: 0.4517 | Val Acc: 0.7724\n",
      "Epoch 25/50 | Train Loss: 0.4133 | Val Loss: 0.4522 | Val Acc: 0.7886\n",
      "Epoch 26/50 | Train Loss: 0.4213 | Val Loss: 0.4534 | Val Acc: 0.7724\n",
      "Epoch 27/50 | Train Loss: 0.4030 | Val Loss: 0.4541 | Val Acc: 0.7642\n",
      "Epoch 28/50 | Train Loss: 0.4002 | Val Loss: 0.4564 | Val Acc: 0.7805\n",
      "Epoch 29/50 | Train Loss: 0.4014 | Val Loss: 0.4592 | Val Acc: 0.7805\n",
      "Epoch 30/50 | Train Loss: 0.3884 | Val Loss: 0.4533 | Val Acc: 0.7805\n",
      "Epoch 31/50 | Train Loss: 0.3965 | Val Loss: 0.4547 | Val Acc: 0.7805\n",
      "Epoch 32/50 | Train Loss: 0.3931 | Val Loss: 0.4584 | Val Acc: 0.7805\n",
      "Epoch 33/50 | Train Loss: 0.3907 | Val Loss: 0.4621 | Val Acc: 0.7724\n",
      "Epoch 34/50 | Train Loss: 0.3997 | Val Loss: 0.4658 | Val Acc: 0.7805\n",
      "Epoch 35/50 | Train Loss: 0.3894 | Val Loss: 0.4646 | Val Acc: 0.7805\n",
      "Epoch 36/50 | Train Loss: 0.3929 | Val Loss: 0.4669 | Val Acc: 0.7642\n",
      "Epoch 37/50 | Train Loss: 0.3849 | Val Loss: 0.4644 | Val Acc: 0.7642\n",
      "Epoch 38/50 | Train Loss: 0.3826 | Val Loss: 0.4690 | Val Acc: 0.7642\n",
      "Epoch 39/50 | Train Loss: 0.3860 | Val Loss: 0.4682 | Val Acc: 0.7724\n",
      "Epoch 40/50 | Train Loss: 0.3716 | Val Loss: 0.4723 | Val Acc: 0.7642\n",
      "Epoch 41/50 | Train Loss: 0.3756 | Val Loss: 0.4742 | Val Acc: 0.7724\n",
      "Epoch 42/50 | Train Loss: 0.3806 | Val Loss: 0.4721 | Val Acc: 0.7561\n",
      "Epoch 43/50 | Train Loss: 0.3736 | Val Loss: 0.4746 | Val Acc: 0.7642\n",
      "Epoch 44/50 | Train Loss: 0.3715 | Val Loss: 0.4773 | Val Acc: 0.7561\n",
      "Epoch 45/50 | Train Loss: 0.3653 | Val Loss: 0.4776 | Val Acc: 0.7480\n",
      "Epoch 46/50 | Train Loss: 0.3624 | Val Loss: 0.4785 | Val Acc: 0.7561\n",
      "Epoch 47/50 | Train Loss: 0.3585 | Val Loss: 0.4773 | Val Acc: 0.7724\n",
      "Epoch 48/50 | Train Loss: 0.3775 | Val Loss: 0.4822 | Val Acc: 0.7480\n",
      "Epoch 49/50 | Train Loss: 0.3596 | Val Loss: 0.4862 | Val Acc: 0.7480\n",
      "Epoch 50/50 | Train Loss: 0.3592 | Val Loss: 0.4856 | Val Acc: 0.7398\n",
      "\n",
      "=== 딥러닝 모델 (PyTorch) ===\n",
      "정확도: 0.7403\n",
      "F1 Score: 0.6429\n",
      "Precision: 0.6316\n",
      "Recall: 0.6545\n",
      "Confusion Matrix:\n",
      "[[78 21]\n",
      " [19 36]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# 검증 세트 분리 (스케일링된 데이터 사용)\n",
    "X_train_sub, X_val, y_train_sub, y_val = train_test_split(\n",
    "    X_train_scaled, y_train, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 데이터 텐서 변환 (스케일링된 데이터만 사용)\n",
    "X_train_sub_tensor = torch.tensor(X_train_sub, dtype=torch.float32)\n",
    "y_train_sub_tensor = torch.tensor(y_train_sub.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# DataLoader 생성 (배치 단위 데이터 처리)\n",
    "# DataLoader 생성\n",
    "train_dataset = TensorDataset(X_train_sub_tensor, y_train_sub_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True) # 훈련 데이터 로더\n",
    "val_loader = DataLoader(val_dataset, batch_size=32) # 검증 데이터 로더\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "print(\"\\n=== pytorch 데이터셋 Shape ===\")\n",
    "print(\"X_train_sub_tensor shape:\", X_train_sub_tensor.shape)\n",
    "print(\"y_train_sub_tensor shape:\", y_train_sub_tensor.shape)\n",
    "print(\"X_val_tensor shape:\", X_val_tensor.shape)\n",
    "print(\"y_val_tensor shape:\", y_val_tensor.shape)\n",
    "print(\"X_test_tensor shape:\", X_test_tensor.shape)\n",
    "print(\"y_test_tensor shape:\", y_test_tensor.shape)\n",
    "print(\"\\n\")\n",
    "\n",
    "# 신경망 정의 (이진 분류기)\n",
    "class HeartDiseaseClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(HeartDiseaseClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)  # 입력층 -> 은닉층 1 (64개 뉴런)\n",
    "        self.fc2 = nn.Linear(64, 32)         # 은닉층 1 -> 은닉층 2 (32개 뉴런)\n",
    "        self.fc3 = nn.Linear(32, 1)          # 은닉층 2 -> 출력층 (1개 뉴런)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))         # ReLU 활성화\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))      # 출력층에 시그모이드 적용\n",
    "        return x\n",
    "\n",
    "# 모델 초기화, 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HeartDiseaseClassifier(input_dim=X_train_scaled.shape[1]).to(device) # 입력차원 자동 설정\n",
    "criterion = nn.BCELoss() # 이진 교차 엔트로피 손실 함수\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) #Adam 옵티마이저\n",
    "\n",
    "# 학습 루프\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    # 훈련 단계\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad() # 기울기 초기화\n",
    "        outputs = model(inputs) # 순전파\n",
    "        loss = criterion(outputs, labels) # 손실 계산\n",
    "        loss.backward() # 역전파\n",
    "        optimizer.step() # 가중치 업데이트\n",
    "        train_loss += loss.item() #손실 누적\n",
    "    \n",
    "    # 검증 단계\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad(): # 기울기 계산 비활\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs, labels).item() # 검증 손실 계산\n",
    "            predicted = (outputs > 0.5).float() # 0.5를 기준으로 예측 클래스 결정\n",
    "            correct += (predicted == labels).sum().item() # 정확히 예측한 개수\n",
    "            total += labels.size(0) # 전체 데이터 개수\n",
    "    \n",
    "    # 에포크당 결과 출력\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "          f\"Train Loss: {train_loss/len(train_loader):.4f} | \"\n",
    "          f\"Val Loss: {val_loss/len(val_loader):.4f} | \"\n",
    "          f\"Val Acc: {correct/total:.4f}\")\n",
    "\n",
    "# 테스트 평가\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_proba = model(X_test_tensor.to(device)) # 테스트 데이터 예측 확률\n",
    "    y_pred_dl = (y_pred_proba > 0.5).float().cpu().numpy().flatten() # 이진 예측값으로 변환\n",
    "\n",
    "# 성능 지표 (정확도, 혼동행렬, F1, Precision, Recall)\n",
    "accuracy = accuracy_score(y_test, y_pred_dl)\n",
    "cm_dl = confusion_matrix(y_test, y_pred_dl)\n",
    "f1 = f1_score(y_test, y_pred_dl)\n",
    "precision = precision_score(y_test, y_pred_dl)\n",
    "recall = recall_score(y_test, y_pred_dl)\n",
    "\n",
    "print(\"\\n=== 딥러닝 모델 (PyTorch) ===\")\n",
    "print(f\"정확도: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dcc43f-d03f-4976-9297-64db4cb14867",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
